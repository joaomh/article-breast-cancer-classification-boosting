cff-version: 1.2.0
message: "If you use this work, please cite it as below."
authors:
  - family-names: Herrera Pinheiro
    given-names: Jo√£o Manoel
  - family-names: Becker
    given-names: Marcelo
title: "Breast Cancer Classification Using Gradient Boosting Algorithms Focusing on Reducing the False Negative and SHAP for Explainability"
abstract: "Cancer is one of the diseases that kill the most women in the world, with breast cancer being responsible for the highest number of cancer cases and consequently deaths. However, it can be prevented by early detection and, consequently, early treatment. Any development for detection or prediction of this kind of cancer is important for a better healthy life. Many studies focus on a model with high accuracy in cancer prediction, but sometimes accuracy alone may not always be a reliable metric. This study implies an investigative approach to studying the performance of different machine learning algorithms based on boosting to predict breast cancer focusing on the recall metric. Boosting machine learning algorithms has been proven to be an effective tool for detecting medical diseases. The dataset of the University of California, Irvine (UCI) repository has been utilized to train and test the model classifier that contains their attributes. The main objective of this study is to use state-of-the-art boosting algorithms such as AdaBoost, XGBoost, CatBoost and LightGBM to predict and diagnose breast cancer and to find the most effective metric regarding recall, ROC-AUC, and confusion matrix. Furthermore, previous studies have applied Optuna to individual algorithms like XGBoost or LightGBM, but no prior research has collectively examined all four boosting algorithms within a unified Optuna framework, a library for hyperparameter optimization, and the SHAP method to improve the interpretability of our model, which can be used as a support to identify and predict breast cancer. We were able to improve AUC or recall for all the models and reduce the False Negative for AdaBoost and LightGBM; the final AUC was more than 99.41% for all models."
journal: "Inteligencia Artificial"
volume: 28
issue: 75
year: 2024
month: 12
start: 63
end: 80
doi: 10.4114/intartif.vol28iss75pp63-80
url: https://journal.iberamia.org/index.php/intartif/article/view/1637
